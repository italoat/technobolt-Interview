import streamlit as st
import google.generativeai as genai
import fitz
import time
import speech_recognition as sr

# --- CONFIGURA√á√ÉO DE UI ---
st.set_page_config(page_title="Interview Co-Pilot | Autonomous Edition", page_icon="‚ö°", layout="wide")

st.markdown("""
    <style>
    .main { background-color: #0d1117; color: #e6edf3; }
    .streaming-card {
        background: #161b22;
        border-radius: 12px;
        padding: 25px;
        border-left: 6px solid #58a6ff;
        box-shadow: 0 8px 24px rgba(0,0,0,0.4);
        font-size: 1.15rem;
        line-height: 1.6;
        margin-bottom: 20px;
    }
    .status-badge { color: #8b949e; font-size: 0.8rem; font-family: monospace; display: block; margin-bottom: 15px; }
    .listening-pulse { color: #3fb950; font-weight: bold; animation: pulse 1.5s infinite; }
    @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>
    """, unsafe_allow_html=True)

MOTORES = [
    "models/gemini-flash-latest",
    "models/gemini-2.0-flash", 
    "models/gemini-2.5-flash", 
    "models/gemini-3-flash-preview"

]

# Palavras-gatilho que voc√™ vai usar para avisar a IA que a pergunta acabou
GATILHOS = ["certo", "ok", "vamos l√°", "entendi", "perfeito", "pode mandar"]

def extract_cv_content(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    return " ".join([page.get_text() for page in doc])

def generate_streaming_response(api_key, cv_context, question_text):
    genai.configure(api_key=api_key)
    
    gen_config = {
        "temperature": 0.2, 
        "top_p": 0.8
    }
    
    system_instruction = f"""
    PERSONA DIN√ÇMICA: Assuma a identidade, o nome, a senioridade, as forma√ß√µes acad√™micas, as certifica√ß√µes e o hist√≥rico profissional exato contido no documento abaixo. Voc√™ √© o candidato sendo entrevistado.
    
    CONTEXTO DO CURR√çCULO:
    {cv_context}

    DIRETRIZES DE RESPOSTA (ESTRITO):
    1. IDENTIDADE: Voc√™ √© o entrevistado. Fale sempre na primeira pessoa do singular ("Eu desenvolvi", "Minha forma√ß√£o em..."). Nunca diga que √© uma IA.
    2. PROVA DE EXPERI√äNCIA: OBRIGATORIAMENTE cite a empresa, projeto, certificado ou stack (Python, AWS, Oracle, NiFi) do curr√≠culo onde adquiriu a experi√™ncia.
    3. FLU√çDEZ: Seja conversacional, direto e pragm√°tico. 
    4. TAMANHO: Racioc√≠nio conciso (3 a 5 frases completas), indo direto ao ponto da pergunta.
    
    PERGUNTA DO ENTREVISTADOR (Transcrita):
    "{question_text}"
    """

    for model_name in MOTORES:
        try:
            model = genai.GenerativeModel(model_name=model_name, generation_config=gen_config)
            # Como a transcri√ß√£o j√° foi feita localmente, passamos apenas o texto (muito mais r√°pido)
            response = model.generate_content(system_instruction, stream=True)
            return response, model_name
        except Exception as e:
            if "429" in str(e): 
                continue
            return None, f"Erro: {str(e)}"
    
    return None, "Limite Global Excedido"

# --- INTERFACE E L√ìGICA DE ESTADO ---
if 'history' not in st.session_state:
    st.session_state.history = []
if 'is_listening' not in st.session_state:
    st.session_state.is_listening = False

with st.sidebar:
    st.header("‚öôÔ∏è Setup do Candidato")
    api_key = st.text_input("Gemini API Key", type="password")
    cv_file = st.file_uploader("Upload do Curr√≠culo (PDF)", type="pdf")
    
    if cv_file and 'cv_text' not in st.session_state:
        st.session_state.cv_text = extract_cv_content(cv_file)
        st.success("Identidade Extra√≠da com Sucesso!")
    
    st.divider()
    st.info("üí° **Como funciona agora:**\nA m√°quina escutar√° em loop. Tudo que o recrutador disser ser√° acumulado num buffer. Quando voc√™ disser apenas **'Certo'**, **'Ok'** ou **'Vamos l√°'**, ela pega o buffer, gera a resposta e limpa a mem√≥ria para a pr√≥xima pergunta.")

st.title("üéôÔ∏è Interview Co-Pilot (Autonomous)")

col_main, col_hist = st.columns([2, 1])

with col_main:
    # Bot√£o de controle de estado (Start/Stop)
    if not st.session_state.is_listening:
        if st.button("‚ñ∂Ô∏è Iniciar Entrevista", use_container_width=True, type="primary"):
            st.session_state.is_listening = True
            st.rerun()
    else:
        if st.button("‚èπÔ∏è Pausar Entrevista", use_container_width=True):
            st.session_state.is_listening = False
            st.rerun()

    status_ui = st.empty()
    transcript_ui = st.empty()
    response_ui = st.empty()

    # O LOOP DE ESCUTA AUT√îNOMA
    if st.session_state.is_listening:
        if not api_key or 'cv_text' not in st.session_state:
            st.error("‚ö†Ô∏è Chave API ou Curr√≠culo ausentes.")
            st.session_state.is_listening = False
            st.rerun()

        recognizer = sr.Recognizer()
        microphone = sr.Microphone()
        
        # Ajusta o ru√≠do ambiente inicial (crucial para o VAD funcionar bem)
        with microphone as source:
            status_ui.markdown("<span class='listening-pulse'>üîÑ Calibrando ru√≠do ambiente... aguarde 2s.</span>", unsafe_allow_html=True)
            recognizer.adjust_for_ambient_noise(source, duration=2)
        
        # Buffer para acumular as partes da pergunta do recrutador
        question_buffer = []

        while st.session_state.is_listening:
            status_ui.markdown("<span class='listening-pulse'>üéôÔ∏è Escutando ativamente... (Diga 'Ok' ou 'Certo' para responder)</span>", unsafe_allow_html=True)
            
            try:
                with microphone as source:
                    # Escuta at√© detectar um per√≠odo de sil√™ncio
                    audio = recognizer.listen(source, timeout=None, phrase_time_limit=15)
                
                status_ui.markdown("<span class='status-badge'>Processando fala...</span>", unsafe_allow_html=True)
                # Usa a API gratuita do Google para transcrever r√°pido
                text = recognizer.recognize_google(audio, language="pt-BR").lower().strip()
                
                # Verifica se a frase dita √© um dos nossos gatilhos
                is_trigger = any(trigger == text for trigger in GATILHOS)
                
                if is_trigger:
                    if not question_buffer:
                        transcript_ui.warning("Gatilho detectado, mas nenhuma pergunta foi ouvida antes.")
                        continue
                    
                    status_ui.markdown("<span class='status-badge'>Gatilho acionado! Gerando resposta...</span>", unsafe_allow_html=True)
                    full_question = " ".join(question_buffer)
                    transcript_ui.info(f"**Pergunta capturada:** {full_question}")
                    
                    # Chama o Gemini
                    response_container = response_ui.container()
                    stream_response, motor = generate_streaming_response(api_key, st.session_state.cv_text, full_question)
                    
                    if stream_response:
                        with response_container:
                            st.markdown(f"<span class='status-badge'>MOTOR EM USO: {motor}</span>", unsafe_allow_html=True)
                            
                            def stream_parser():
                                for chunk in stream_response:
                                    try:
                                        if chunk.text: yield chunk.text
                                    except ValueError: pass
                            
                            st.markdown("<div class='streaming-card'>", unsafe_allow_html=True)
                            full_text = st.write_stream(stream_parser)
                            st.markdown("</div>", unsafe_allow_html=True)
                            
                            # Salva hist√≥rico e limpa buffer
                            st.session_state.history.append({"q": full_question, "a": full_text, "time": time.strftime("%H:%M:%S")})
                            question_buffer = [] # Zera para a pr√≥xima pergunta
                    else:
                        st.error("Falha ao contatar a API do Gemini.")
                
                else:
                    # Se n√£o √© gatilho, assume que √© o recrutador falando e acumula no buffer
                    question_buffer.append(text)
                    transcript_ui.success(f"**Ouvido at√© agora:** {' '.join(question_buffer)}")

            except sr.WaitTimeoutError:
                continue
            except sr.UnknownValueError:
                # Sil√™ncio ou ru√≠do irreconhec√≠vel, apenas ignora
                continue
            except Exception as e:
                status_ui.error(f"Erro no √°udio: {e}")
                time.sleep(2)

with col_hist:
    st.subheader("üìö Hist√≥rico R√°pido")
    if st.session_state.history:
        for item in reversed(st.session_state.history):
            with st.expander(f"Turno - {item['time']}", expanded=False):
                st.markdown(f"**Q:** {item['q']}")
                st.markdown(f"**R:** {item['a']}")
    else:
        st.write("Aguardando intera√ß√µes...")
